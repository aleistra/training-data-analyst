{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# MNIST Image Classification with TensorFlow\n",
    "\n",
    "This notebook demonstrates how to implement a simple linear image models on MNIST using Estimator.\n",
    "<hr/>\n",
    "This <a href=\"mnist_models.ipynb\">companion notebook</a> extends the basic harness of this notebook to a variety of models including DNN, CNN, dropout, pooling etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Exploring the data\n",
    "\n",
    "Let's download MNIST data and examine the shape. We will need these numbers ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HEIGHT = 28\n",
    "WIDTH = 28\n",
    "NCLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (60000, 28, 28)\n",
      "y_train.shape = (60000, 10)\n",
      "x_test.shape = (10000, 28, 28)\n",
      "y_test.shape = (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Get mnist data\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Scale our features between 0 and 1\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0 \n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y = y_train, num_classes = NCLASSES)\n",
    "y_test = tf.keras.utils.to_categorical(y = y_test, num_classes = NCLASSES)\n",
    "\n",
    "print(\"x_train.shape = {}\".format(x_train.shape))\n",
    "print(\"y_train.shape = {}\".format(y_train.shape))\n",
    "print(\"x_test.shape = {}\".format(x_test.shape))\n",
    "print(\"y_test.shape = {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "IMGNO = 12\n",
    "plt.imshow(x_test[IMGNO].reshape(HEIGHT, WIDTH));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Define the model.\n",
    "Let's start with a very simple linear classifier. All our models will have this basic interface -- they will take an image and return probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Build Keras Model Using Keras Sequential API\n",
    "def linear_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape = [HEIGHT, WIDTH], name = \"image\"))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units = NCLASSES, activation = tf.nn.softmax, name = \"probabilities\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape = [HEIGHT, WIDTH], name = \"image\"))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(64, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.1))\n",
    "    model.add(tf.keras.layers.Dense(units = NCLASSES, activation = tf.nn.softmax, name = \"probabilities\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Write Input Functions\n",
    "\n",
    "As usual, we need to specify input functions for training, evaluation, and predicition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create training input function\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {\"image\": x_train},\n",
    "    y = y_train,\n",
    "    batch_size = 100,\n",
    "    num_epochs = None,\n",
    "    shuffle = True,\n",
    "    queue_capacity = 5000\n",
    "  )\n",
    "\n",
    "# Create evaluation input function\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {\"image\": x_test},\n",
    "    y = y_test,\n",
    "    batch_size = 100,\n",
    "    num_epochs = 1,\n",
    "    shuffle = False,\n",
    "    queue_capacity = 5000\n",
    "  )\n",
    "\n",
    "# Create serving input function for inference\n",
    "def serving_input_fn():\n",
    "    placeholders = {\"image\": tf.placeholder(dtype = tf.float32, shape = [None, HEIGHT, WIDTH])}\n",
    "    features = placeholders # as-is\n",
    "    return tf.estimator.export.ServingInputReceiver(features = features, receiver_tensors = placeholders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Create train_and_evaluate function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    " tf.estimator.train_and_evaluate does distributed training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(output_dir, hparams):\n",
    "    # Build Keras model\n",
    "    model = linear_model()\n",
    "        \n",
    "    # Compile Keras model with optimizer, loss function, and eval metrics\n",
    "    model.compile(\n",
    "        optimizer = \"adam\",\n",
    "        loss = \"categorical_crossentropy\",\n",
    "        metrics = [\"accuracy\"])\n",
    "        \n",
    "    # Convert Keras model to an Estimator\n",
    "    estimator = tf.keras.estimator.model_to_estimator(\n",
    "        keras_model = model, \n",
    "        model_dir = output_dir)\n",
    "\n",
    "    # Set estimator's train_spec to use train_input_fn and train for so many steps\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn = train_input_fn,\n",
    "        max_steps = hparams[\"train_steps\"])\n",
    "\n",
    "    # Create exporter that uses serving_input_fn to create saved_model for serving\n",
    "    exporter = tf.estimator.LatestExporter(\n",
    "        name = \"exporter\", \n",
    "        serving_input_receiver_fn = serving_input_fn)\n",
    "\n",
    "    # Set estimator's eval_spec to use eval_input_fn and export saved_model\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn = eval_input_fn,\n",
    "        steps = None,\n",
    "        exporters = exporter)\n",
    "\n",
    "    # Run train_and_evaluate loop\n",
    "    tf.estimator.train_and_evaluate(\n",
    "        estimator = estimator, \n",
    "        train_spec = train_spec, \n",
    "        eval_spec = eval_spec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_dnn(output_dir, hparams):\n",
    "    # Build Keras model\n",
    "    model = dnn_model()\n",
    "        \n",
    "    # Compile Keras model with optimizer, loss function, and eval metrics\n",
    "    model.compile(\n",
    "        optimizer = \"adam\",\n",
    "        loss = \"categorical_crossentropy\",\n",
    "        metrics = [\"accuracy\"])\n",
    "        \n",
    "    # Convert Keras model to an Estimator\n",
    "    estimator = tf.keras.estimator.model_to_estimator(\n",
    "        keras_model = model, \n",
    "        model_dir = output_dir)\n",
    "\n",
    "    # Set estimator's train_spec to use train_input_fn and train for so many steps\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn = train_input_fn,\n",
    "        max_steps = hparams[\"train_steps\"])\n",
    "\n",
    "    # Create exporter that uses serving_input_fn to create saved_model for serving\n",
    "    exporter = tf.estimator.LatestExporter(\n",
    "        name = \"exporter\", \n",
    "        serving_input_receiver_fn = serving_input_fn)\n",
    "\n",
    "    # Set estimator's eval_spec to use eval_input_fn and export saved_model\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn = eval_input_fn,\n",
    "        steps = None,\n",
    "        exporters = exporter)\n",
    "\n",
    "    # Run train_and_evaluate loop\n",
    "    tf.estimator.train_and_evaluate(\n",
    "        estimator = estimator, \n",
    "        train_spec = train_spec, \n",
    "        eval_spec = eval_spec)\n",
    "    \n",
    "    preds = model.predict_classes(x_test)\n",
    "    actuals = y_test\n",
    "        \n",
    "    return (preds, actuals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plain_keras():\n",
    "    model = dnn_model()\n",
    "        \n",
    "    # Compile Keras model with optimizer, loss function, and eval metrics\n",
    "    model.compile(\n",
    "        optimizer = \"adam\",\n",
    "        loss = \"categorical_crossentropy\",\n",
    "        metrics = [\"accuracy\"])\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict_classes(x_test)\n",
    "    \n",
    "    return(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 7s 117us/sample - loss: 0.2693 - acc: 0.9208\n"
     ]
    }
   ],
   "source": [
    "(yt, yp) = plain_keras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [np.argmax(yy) for yy in yt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    with sess.as_default():\n",
    "        cm = tf.confusion_matrix(yp, y_true).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 967,    0,    3,    0,    1,    3,    6,    1,    2,    5],\n",
       "       [   0, 1122,    5,    0,    2,    1,    4,   12,    7,    6],\n",
       "       [   3,    3, 1000,    6,    4,    0,    1,   16,    7,    2],\n",
       "       [   1,    1,    5,  977,    0,   11,    0,    5,   14,   10],\n",
       "       [   0,    0,    3,    0,  935,    2,    7,    0,    2,   18],\n",
       "       [   3,    2,    1,    3,    3,  861,   20,    0,   10,    3],\n",
       "       [   3,    1,    2,    0,    7,    1,  915,    0,    1,    0],\n",
       "       [   1,    0,    8,    8,    1,    3,    0,  982,    6,    7],\n",
       "       [   1,    5,    4,   15,    5,    8,    5,    1,  924,   10],\n",
       "       [   1,    1,    1,    1,   24,    2,    0,   11,    1,  948]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is the main() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_every_n_hours': 10000, '_service': None, '_is_chief': True, '_num_ps_replicas': 0, '_master': '', '_save_checkpoints_secs': 600, '_device_fn': None, '_train_distribute': None, '_evaluation_master': '', '_task_type': 'worker', '_tf_random_seed': None, '_task_id': 0, '_model_dir': 'mnist/learned', '_experimental_distribute': None, '_num_worker_replicas': 1, '_protocol': None, '_keep_checkpoint_max': 5, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_eval_distribute': None, '_log_step_count_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe46c1c66a0>, '_global_id_in_cluster': 0}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='mnist/learned/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: ('mnist/learned/keras/keras_model.ckpt',)\n",
      "INFO:tensorflow:Warm-starting variable: probabilities/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_5; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_1; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_4; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/beta_1; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/beta_2; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_3; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: probabilities/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/decay; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/lr; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/iterations; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_2; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into mnist/learned/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.3426857, step = 1\n",
      "INFO:tensorflow:global_step/sec: 251.369\n",
      "INFO:tensorflow:loss = 0.64090616, step = 101 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.592\n",
      "INFO:tensorflow:loss = 0.70877314, step = 201 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.585\n",
      "INFO:tensorflow:loss = 0.4385703, step = 301 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.741\n",
      "INFO:tensorflow:loss = 0.40469712, step = 401 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.13\n",
      "INFO:tensorflow:loss = 0.41837624, step = 501 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.358\n",
      "INFO:tensorflow:loss = 0.3536095, step = 601 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.123\n",
      "INFO:tensorflow:loss = 0.42106223, step = 701 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.531\n",
      "INFO:tensorflow:loss = 0.40628457, step = 801 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.68\n",
      "INFO:tensorflow:loss = 0.30991444, step = 901 (0.266 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into mnist/learned/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-07-25T17:28:50Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from mnist/learned/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-07-25-17:28:51\n",
      "INFO:tensorflow:Saving dict for global step 1000: categorical_accuracy = 0.9135, global_step = 1000, loss = 0.32010755\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: mnist/learned/model.ckpt-1000\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from mnist/learned/model.ckpt-1000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: mnist/learned/export/exporter/temp-b'1564075731'/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 0.30422142.\n"
     ]
    }
   ],
   "source": [
    "OUTDIR = \"mnist/learned\"\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "\n",
    "hparams = {\"train_steps\": 1000, \"learning_rate\": 0.01}\n",
    "train_and_evaluate(OUTDIR, hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got:\n",
    "\n",
    "`Saving dict for global step 1000: categorical_accuracy = 0.9112, global_step = 1000, loss = 0.32516304`\n",
    "\n",
    "In other words, we achieved 91.12% accuracy with the simple linear model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving dict for global step 1000: categorical_accuracy = 0.9131, global_step = 1000, loss = 0.32085687"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_every_n_hours': 10000, '_service': None, '_is_chief': True, '_num_ps_replicas': 0, '_master': '', '_save_checkpoints_secs': 600, '_device_fn': None, '_train_distribute': None, '_evaluation_master': '', '_task_type': 'worker', '_tf_random_seed': None, '_task_id': 0, '_model_dir': 'mnist/learned', '_experimental_distribute': None, '_num_worker_replicas': 1, '_protocol': None, '_keep_checkpoint_max': 5, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_eval_distribute': None, '_log_step_count_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe4867c7518>, '_global_id_in_cluster': 0}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='mnist/learned/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: ('mnist/learned/keras/keras_model.ckpt',)\n",
      "INFO:tensorflow:Warm-starting variable: Adam/beta_1; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_7; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_6; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_12; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_16; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_9; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_13; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/beta_2; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_3; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_26/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_5; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/lr; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/iterations; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_2; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_15; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_27/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: probabilities/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_26/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_8; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_1; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_11; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_14; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_10; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: probabilities/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_17; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/decay; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_27/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_4; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into mnist/learned/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.3682303, step = 1\n",
      "INFO:tensorflow:global_step/sec: 144.253\n",
      "INFO:tensorflow:loss = 0.41008857, step = 101 (0.695 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.8\n",
      "INFO:tensorflow:loss = 0.35381028, step = 201 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.659\n",
      "INFO:tensorflow:loss = 0.21485078, step = 301 (0.651 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.137\n",
      "INFO:tensorflow:loss = 0.2771442, step = 401 (0.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.972\n",
      "INFO:tensorflow:loss = 0.16851145, step = 501 (0.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.029\n",
      "INFO:tensorflow:loss = 0.18392912, step = 601 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.823\n",
      "INFO:tensorflow:loss = 0.13770872, step = 701 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.186\n",
      "INFO:tensorflow:loss = 0.16268045, step = 801 (0.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.771\n",
      "INFO:tensorflow:loss = 0.12565714, step = 901 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.17\n",
      "INFO:tensorflow:loss = 0.09649076, step = 1001 (0.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.322\n",
      "INFO:tensorflow:loss = 0.16203535, step = 1101 (0.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.632\n",
      "INFO:tensorflow:loss = 0.08299712, step = 1201 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.768\n",
      "INFO:tensorflow:loss = 0.098811716, step = 1301 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.487\n",
      "INFO:tensorflow:loss = 0.08519204, step = 1401 (0.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.136\n",
      "INFO:tensorflow:loss = 0.13748173, step = 1501 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.338\n",
      "INFO:tensorflow:loss = 0.15140642, step = 1601 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.136\n",
      "INFO:tensorflow:loss = 0.10873172, step = 1701 (0.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.903\n",
      "INFO:tensorflow:loss = 0.1432514, step = 1801 (0.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.536\n",
      "INFO:tensorflow:loss = 0.027598023, step = 1901 (0.511 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into mnist/learned/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-07-25T19:23:57Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from mnist/learned/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-07-25-19:23:57\n",
      "INFO:tensorflow:Saving dict for global step 2000: categorical_accuracy = 0.9755, global_step = 2000, loss = 0.0808818\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: mnist/learned/model.ckpt-2000\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from mnist/learned/model.ckpt-2000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: mnist/learned/export/exporter/temp-b'1564082637'/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 0.086774305.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_estimator.python.estimator.api.estimator' has no attribute 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-a340b56d20f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"train_steps\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"learning_rate\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactuals\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate_dnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTDIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-91-d9561e2ca0a8>\u001b[0m in \u001b[0;36mtrain_and_evaluate_dnn\u001b[0;34m(output_dir, hparams)\u001b[0m\n\u001b[1;32m     36\u001b[0m         eval_spec = eval_spec)\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow_estimator.python.estimator.api.estimator' has no attribute 'train'"
     ]
    }
   ],
   "source": [
    "OUTDIR = \"mnist/learned\"\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "\n",
    "hparams = {\"train_steps\": 2000, \"learning_rate\": 0.01}\n",
    "(preds, actuals) = train_and_evaluate_dnn(OUTDIR, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_every_n_hours': 10000, '_service': None, '_is_chief': True, '_num_ps_replicas': 0, '_master': '', '_save_checkpoints_secs': 600, '_device_fn': None, '_train_distribute': None, '_evaluation_master': '', '_task_type': 'worker', '_tf_random_seed': None, '_task_id': 0, '_model_dir': 'mnist/learned', '_experimental_distribute': None, '_num_worker_replicas': 1, '_protocol': None, '_keep_checkpoint_max': 5, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_eval_distribute': None, '_log_step_count_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe4872c6198>, '_global_id_in_cluster': 0}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='mnist/learned/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: ('mnist/learned/keras/keras_model.ckpt',)\n",
      "INFO:tensorflow:Warm-starting variable: Adam/beta_1; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_5; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_6; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_12; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_18/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_16; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_9; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/beta_2; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_3; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_19/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_7; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_19/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/lr; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/iterations; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_2; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_15; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: probabilities/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_13; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_8; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_1; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_11; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_18/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_10; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: probabilities/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_17; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/decay; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_14; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_4; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into mnist/learned/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.3716831, step = 1\n",
      "INFO:tensorflow:global_step/sec: 144.853\n",
      "INFO:tensorflow:loss = 0.29144332, step = 101 (0.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.374\n",
      "INFO:tensorflow:loss = 0.28960586, step = 201 (0.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.705\n",
      "INFO:tensorflow:loss = 0.3065926, step = 301 (0.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.607\n",
      "INFO:tensorflow:loss = 0.1410815, step = 401 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.467\n",
      "INFO:tensorflow:loss = 0.13559127, step = 501 (0.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.466\n",
      "INFO:tensorflow:loss = 0.06756234, step = 601 (0.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.019\n",
      "INFO:tensorflow:loss = 0.08785776, step = 701 (0.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.241\n",
      "INFO:tensorflow:loss = 0.15099518, step = 801 (0.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.387\n",
      "INFO:tensorflow:loss = 0.17047945, step = 901 (0.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.314\n",
      "INFO:tensorflow:loss = 0.14547862, step = 1001 (0.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.582\n",
      "INFO:tensorflow:loss = 0.050312486, step = 1101 (0.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.719\n",
      "INFO:tensorflow:loss = 0.105642945, step = 1201 (0.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.184\n",
      "INFO:tensorflow:loss = 0.106048405, step = 1301 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.878\n",
      "INFO:tensorflow:loss = 0.093343645, step = 1401 (0.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.691\n",
      "INFO:tensorflow:loss = 0.100078166, step = 1501 (0.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.501\n",
      "INFO:tensorflow:loss = 0.09192466, step = 1601 (0.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.167\n",
      "INFO:tensorflow:loss = 0.06241787, step = 1701 (0.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.815\n",
      "INFO:tensorflow:loss = 0.07273339, step = 1801 (0.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.134\n",
      "INFO:tensorflow:loss = 0.23439103, step = 1901 (0.548 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into mnist/learned/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-07-25T17:39:43Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from mnist/learned/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-07-25-17:39:43\n",
      "INFO:tensorflow:Saving dict for global step 2000: categorical_accuracy = 0.9735, global_step = 2000, loss = 0.086029805\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: mnist/learned/model.ckpt-2000\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from mnist/learned/model.ckpt-2000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: mnist/learned/export/exporter/temp-b'1564076383'/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 0.07089193.\n"
     ]
    }
   ],
   "source": [
    "OUTDIR = \"mnist/learned\"\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "\n",
    "hparams = {\"train_steps\": 2000, \"learning_rate\": 0.01}\n",
    "(x_test, yhat, y) = train_and_evaluate_dnn(OUTDIR, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, ..., 0, 0, 4])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt1 == xt2.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07035933, 0.13181132, 0.09147464, 0.14828543, 0.12785229,\n",
       "       0.09173739, 0.0820067 , 0.09393556, 0.06346026, 0.09907712],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(yhat[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = [np.argmax(yh) for yh in yhat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 8, 6, 6, 8]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds[:5]\n",
    "\n",
    "# 6, 9, 4, 5, 9\n",
    "# 8, 3, 3, 9, 9\n",
    "# 2, 8, 6, 6, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08068436, 0.10411207, 0.09924155, 0.1056537 , 0.10437905,\n",
       "        0.09946482, 0.08825835, 0.0987853 , 0.11129862, 0.10812218],\n",
       "       [0.07035933, 0.13181132, 0.09147464, 0.14828543, 0.12785229,\n",
       "        0.09173739, 0.0820067 , 0.09393556, 0.06346026, 0.09907712],\n",
       "       [0.08047639, 0.08944861, 0.11912595, 0.1252125 , 0.10308643,\n",
       "        0.10109044, 0.10447406, 0.10603986, 0.07659378, 0.09445196],\n",
       "       [0.09131777, 0.09115991, 0.09650643, 0.11250948, 0.09996839,\n",
       "        0.08333775, 0.09256972, 0.12694798, 0.07699932, 0.12868327],\n",
       "       [0.06651994, 0.09042523, 0.0902258 , 0.11480798, 0.09949264,\n",
       "        0.10396718, 0.08482331, 0.11036616, 0.10495665, 0.1344151 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [np.argmax(yy) for yy in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 2, 1, 0, 4]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true[:5]\n",
    "\n",
    "# 7, 2, 1, 0, 4\n",
    "# 7, 2, 1, 0, 4\n",
    "# 7, 2, 1, 0, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/ops/confusion_matrix.py:193: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    with sess.as_default():\n",
    "        cm = tf.confusion_matrix(y_preds, y_true).eval()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,   1,  10,  27,   1,  10,   0,   6,  10,   1],\n",
       "       [203,  78,  17,  37,  12,  96,  25,  57,  18,  11],\n",
       "       [ 51,   0,  80,   8, 153,  42, 300,  75,  31, 134],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   5],\n",
       "       [  0,   7,   1,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [617, 961, 726, 653, 528, 479, 526, 738, 744, 777],\n",
       "       [ 14,  52,  64,   8,  21,  35,  10,  52,  17,  17],\n",
       "       [ 94,  35, 131, 277, 265, 229,  97,  96, 152,  61],\n",
       "       [  0,   1,   3,   0,   2,   1,   0,   4,   2,   3]], dtype=int32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix as skcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,   1,  10,  27,   1,  10,   0,   6,  10,   1],\n",
       "       [203,  78,  17,  37,  12,  96,  25,  57,  18,  11],\n",
       "       [ 51,   0,  80,   8, 153,  42, 300,  75,  31, 134],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   5],\n",
       "       [  0,   7,   1,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [617, 961, 726, 653, 528, 479, 526, 738, 744, 777],\n",
       "       [ 14,  52,  64,   8,  21,  35,  10,  52,  17,  17],\n",
       "       [ 94,  35, 131, 277, 265, 229,  97,  96, 152,  61],\n",
       "       [  0,   1,   3,   0,   2,   1,   0,   4,   2,   3]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skcm(y_preds, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First pass: Saving dict for global step 1000: categorical_accuracy = 0.9489, global_step = 1000, loss = 0.17488453\n",
    "# added one dense layer, 64 units\n",
    "\n",
    "# Second pass (another layer of 32 units): \n",
    "# Saving dict for global step 1000: categorical_accuracy = 0.9516, global_step = 1000, loss = 0.16565359\n",
    "\n",
    "# Third pass: dropout layer with probability 0.5:\n",
    "# Saving dict for global step 1000: categorical_accuracy = 0.9437, global_step = 1000, loss = 0.1882948\n",
    "\n",
    "# Fourth pass: dropout layer with probability 0.1:\n",
    "# Saving dict for global step 1000: categorical_accuracy = 0.9528, global_step = 1000, loss = 0.15361284\n",
    "\n",
    "# Fifth pass: Upped second layer to 64 units:\n",
    "# Saving dict for global step 1000: categorical_accuracy = 0.9539, global_step = 1000, loss = 0.14908159\n",
    "\n",
    "# Sixth pass: Upped first layer to 128 units:\n",
    "# Saving dict for global step 1000: categorical_accuracy = 0.9649, global_step = 1000, loss = 0.11287299\n",
    "\n",
    "# 7th pass: Upped train steps to 2000:\n",
    "# Saving dict for global step 2000: categorical_accuracy = 0.9707, global_step = 2000, loss = 0.094434"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<pre>\n",
    "# Copyright 2017 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "</pre>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
